import os
import re
import streamlit as st
from dotenv import load_dotenv

from langchain_core.documents import Document
from langchain_chroma import Chroma
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough, RunnableLambda
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter

import pandas as pd
import time
from typing import List, Dict, Tuple
from pathlib import Path


# Environment ayarlarÄ±
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

if not api_key:
    st.error("âš ï¸ LÃ¼tfen .env dosyasÄ±na OPENAI_API_KEY ekleyin.")
    st.stop()

# Streamlit config
st.set_page_config(
    page_title="TÃœÄ°K Ä°statistik Chatbot", 
    page_icon="ğŸ“Š",
    layout="wide"
)

st.title("ğŸ“Š TÃ¼rkiye GenÃ§lik, Aile ve YaÅŸlÄ± Ä°statistikleri Chatbot")
st.caption("OpenAI GPT + RAGAS ile performans deÄŸerlendirmeli versiyon")

# Sabitler
CHUNK_SIZE = 800
CHUNK_OVERLAP = 150
TOP_K = 4

# LLM ve Embeddings
llm = ChatOpenAI(
    model="gpt-4o-mini",
    temperature=0,
    max_tokens=1000,
    api_key=api_key
)

embeddings = OpenAIEmbeddings(
    model="text-embedding-3-small",
    api_key=api_key
)

# Session state baÅŸlatma
if "vector_store" not in st.session_state:
    st.session_state.vector_store = None
if "retriever" not in st.session_state:
    st.session_state.retriever = None
if "messages" not in st.session_state:
    st.session_state.messages = []
if "contexts" not in st.session_state:
    st.session_state.contexts = {}

# ============================================
# YARDIMCI FONKSÄ°YONLAR
# ============================================

def extract_metadata_from_filename(filename: str) -> Dict[str, str]:
    """
    Dosya adÄ±ndan kategori ve yÄ±l bilgisini Ã§Ä±karÄ±r.
    Ã–rnek: 'genclik_14.pdf' -> {'kategori': 'genclik', 'yil': '2014'}
    """
    metadata = {"kategori": "bilinmiyor", "yil": "bilinmiyor"}
    
    # Kategoriyi belirle
    if "genclik" in filename.lower():
        metadata["kategori"] = "genclik"
    elif "yasli" in filename.lower():
        metadata["kategori"] = "yasli"
    elif "aile" in filename.lower():
        metadata["kategori"] = "aile"
    
    # YÄ±lÄ± Ã§Ä±kar (14, 15, ... 24 formatÄ±nda)
    year_match = re.search(r'_(\d{2})\.pdf', filename)
    if year_match:
        year_short = year_match.group(1)
        year_full = f"20{year_short}"
        metadata["yil"] = year_full
    
    return metadata

def load_all_pdfs(data_folder: str) -> List[Document]:
    """
    data/ klasÃ¶rÃ¼ndeki tÃ¼m PDF'leri yÃ¼kler ve metadata ekler.
    """
    all_documents = []
    
    if not os.path.exists(data_folder):
        st.error(f"âŒ {data_folder} klasÃ¶rÃ¼ bulunamadÄ±!")
        return all_documents
    
    pdf_files = [f for f in os.listdir(data_folder) if f.lower().endswith('.pdf')]
    
    if not pdf_files:
        st.warning(f"âš ï¸ {data_folder} klasÃ¶rÃ¼nde PDF dosyasÄ± bulunamadÄ±!")
        return all_documents
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for idx, pdf_file in enumerate(pdf_files):
        pdf_path = os.path.join(data_folder, pdf_file)
        status_text.text(f"YÃ¼kleniyor: {pdf_file}")
        
        try:
            loader = PyPDFLoader(pdf_path)
            documents = loader.load()
            
            # Metadata ekle
            file_metadata = extract_metadata_from_filename(pdf_file)
            
            for doc in documents:
                doc.metadata.update({
                    "source": pdf_file,
                    "kategori": file_metadata["kategori"],
                    "yil": file_metadata["yil"]
                })
            
            all_documents.extend(documents)
            
        except Exception as e:
            st.warning(f"âš ï¸ {pdf_file} yÃ¼klenemedi: {str(e)}")
        
        progress_bar.progress((idx + 1) / len(pdf_files))
    
    progress_bar.empty()
    status_text.empty()
    
    return all_documents

def extract_years(text: str):
    years = re.findall(r"\b(20\d{2})\b", text)
    # unique, order-preserving
    seen = set()
    out = []
    for y in years:
        if y not in seen:
            seen.add(y)
            out.append(y)
    return out

def retrieve_docs_smart(question: str) -> List[Document]:
    years = extract_years(question)

    # Adaptif k: karÅŸÄ±laÅŸtÄ±rma varsa k bÃ¼yÃ¼t
    base_k = TOP_K
    k = 12 if len(years) >= 2 else base_k

    docs_all: List[Document] = []

    # YÄ±l varsa: yÄ±l yÄ±l filtreli Ã§ek (en bÃ¼yÃ¼k iyileÅŸtirme)
    if years and st.session_state.vector_store is not None:
        for y in years:
            yr_retriever = st.session_state.vector_store.as_retriever(
                search_kwargs={"k": k, "filter": {"yil": y}}
            )
            docs_all.extend(yr_retriever.invoke(question))

        # Ek: EÄŸer filtreli arama az dÃ¶ndÃ¼rdÃ¼yse, fallback genel arama
        if len(docs_all) < min(4, k):
            fallback = st.session_state.vector_store.as_retriever(
                search_kwargs={"k": k}
            )
            docs_all.extend(fallback.invoke(question))

    else:
        # YÄ±l yoksa normal arama
        docs_all = st.session_state.retriever.invoke(question)

    # Dedupe (aynÄ± chunk tekrar gelmesin)
    seen = set()
    unique_docs = []
    for d in docs_all:
        key = (
            d.metadata.get("source"),
            d.metadata.get("page"),
            d.metadata.get("kategori"),
            d.metadata.get("yil"),
            d.page_content[:120],
        )
        if key not in seen:
            seen.add(key)
            unique_docs.append(d)

    return unique_docs


def create_vector_store(documents: List[Document]) -> Chroma:
    """
    DokÃ¼manlardan vektÃ¶r veritabanÄ± oluÅŸturur.
    """
    with st.spinner("ğŸ“ DokÃ¼manlar parÃ§alanÄ±yor..."):
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=CHUNK_SIZE,
            chunk_overlap=CHUNK_OVERLAP,
            separators=["\n\n", "\n", ".", "!", "?", ",", " ", ""]
        )
        
        splits = text_splitter.split_documents(documents)
        st.info(f"âœ‚ï¸ Toplam {len(splits)} metin parÃ§asÄ± oluÅŸturuldu")
    
    with st.spinner("ğŸ”¢ Embeddings hesaplanÄ±yor..."):
        vector_store = Chroma.from_documents(
            documents=splits,
            embedding=embeddings,
            persist_directory=PERSIST_DIR
        )
    
    return vector_store

def format_docs(docs: List[Document]) -> str:
    """
    Retrieve edilen dokÃ¼manlarÄ± formatlar.
    """
    formatted = []
    for i, doc in enumerate(docs, 1):
        kategori = doc.metadata.get('kategori', 'bilinmiyor')
        yil = doc.metadata.get('yil', 'bilinmiyor')
        content = doc.page_content
        formatted.append(f"[Kaynak {i} - {kategori.upper()} {yil}]\n{content}\n")
    return "\n".join(formatted)

def guard_mismatch(question: str, docs: List[Document]) -> bool:
    """
    True dÃ¶nerse: cevap Ã¼retme, 'bulunamadÄ±' de.
    Basit ama etkili: soru 'nÃ¼fus oranÄ±' isterken context sadece 'baÄŸÄ±mlÄ±lÄ±k oranÄ±' veriyorsa engelle.
    """
    q = question.lower()
    ctx = " ".join(d.page_content for d in docs).lower()

    # Ã–rnek kavram Ã§akÄ±ÅŸmasÄ± 1
    if "yaÅŸlÄ± nÃ¼fus oran" in q and "yaÅŸlÄ± baÄŸÄ±mlÄ±lÄ±k oran" in ctx and "yaÅŸlÄ± nÃ¼fus oran" not in ctx:
        return True

    # Ã–rnek kavram Ã§akÄ±ÅŸmasÄ± 2 (beklenen yaÅŸam sÃ¼resi tÃ¼rleri)
    if "beklenen yaÅŸam sÃ¼resi" in q:
        if "doÄŸuÅŸta" in q and ("65 yaÅŸ" in ctx or "65 yaÅŸÄ±nda" in ctx) and "doÄŸuÅŸta" not in ctx:
            return True
        if ("65 yaÅŸ" in q or "65 yaÅŸÄ±nda" in q) and "doÄŸuÅŸta" in ctx and ("65 yaÅŸ" not in ctx and "65 yaÅŸÄ±nda" not in ctx):
            return True

    return False


# ============================================
BASE_DIR = Path(__file__).resolve().parent
DATA_FOLDER = str(BASE_DIR / "data")
PERSIST_DIR = str(BASE_DIR / "chroma_db")

def init_vector_store():
    if os.path.exists(PERSIST_DIR) and os.listdir(PERSIST_DIR):
        return Chroma(persist_directory=PERSIST_DIR, embedding_function=embeddings)

    documents = load_all_pdfs(DATA_FOLDER)
    if not documents:
        st.error(f"Veri bulunamadÄ±: {DATA_FOLDER}")
        return None

    return create_vector_store(documents)

if st.session_state.vector_store is None:
    st.session_state.vector_store = init_vector_store()

if st.session_state.vector_store is not None and st.session_state.retriever is None:
    st.session_state.retriever = st.session_state.vector_store.as_retriever(
        search_kwargs={"k": TOP_K}
    )


# ============================================
# RAG CHAIN
# ============================================

def create_rag_chain_no_retriever():
    template = """Sen TÃœÄ°K istatistiklerini analiz eden bir uzmansÄ±n.
SADECE verilen baÄŸlam (context) iÃ§indeki ifadeleri kullanarak cevap ver.

BaÄŸlam:
{context}

Soru:
{question}

Kurallar (Ã§ok Ã¶nemli):
- YalnÄ±zca baÄŸlamda aÃ§Ä±kÃ§a geÃ§en bilgileri kullan. Genel bilgi ekleme.
- BaÄŸlamda "dÃ¼nya", "Avrupa", "OECD" gibi ifadeler yoksa bu tÃ¼r karÅŸÄ±laÅŸtÄ±rmalar yapma.
- KavramlarÄ± karÄ±ÅŸtÄ±rma:
  "yaÅŸlÄ± nÃ¼fus oranÄ±" â‰  "yaÅŸlÄ± baÄŸÄ±mlÄ±lÄ±k oranÄ±"
  "beklenen yaÅŸam sÃ¼resi (doÄŸuÅŸta)" â‰  "65 yaÅŸÄ±nda beklenen yaÅŸam sÃ¼resi"
  Soru hangi gÃ¶stergeyi istiyorsa yalnÄ±zca o gÃ¶stergenin deÄŸerini ver.
- EÄŸer sorulan gÃ¶sterge baÄŸlamda yoksa: "Bu bilgi verilen dokÃ¼manlarda bulunmamaktadÄ±r." de.
- Birden fazla yÄ±l isteniyorsa, Ã¶nce 2-3 cÃ¼mleyle Ã¶zeti yaz, sonra kÄ±sa bir tabloyla karÅŸÄ±laÅŸtÄ±r.
- YÄ±llarÄ± doÄŸru eÅŸleÅŸtir. YanlÄ±ÅŸ yÄ±l verme.

Sadece cevabÄ± yaz. Etiket/baÅŸlÄ±k/format ÅŸablonu kullanma.

"""

    prompt = ChatPromptTemplate.from_template(template)
    return prompt | llm | StrOutputParser()


GROUND_TRUTH_MAP = {
    "2020 yÄ±lÄ±nda genÃ§ nÃ¼fus oranÄ± nedir?":
        "2020 yÄ±lÄ±nda genÃ§ nÃ¼fus, toplam nÃ¼fusun %15,4'Ã¼nÃ¼ oluÅŸturdu.",

    "2023 yÄ±lÄ±nda akraba evliliÄŸi oranÄ± nedir?":
        "2023 yÄ±lÄ±nda akraba evliliÄŸi yapanlarÄ±n oranÄ± %8,2 oldu",

    "2014 yÄ±lÄ±nda boÅŸanan Ã§ift sayÄ±sÄ± kaÃ§tÄ±r?":
        "BoÅŸanan Ã§ift sayÄ±sÄ± 2014 yÄ±lÄ±nda 130 bin 913 oldu",

    "2018 yÄ±lÄ±nda genÃ§lerde iÅŸsizlik oranÄ± nedir?":
        "2018 yÄ±lÄ±nda genÃ§lerde iÅŸsizlik oranÄ± %20,3 oldu",

    "2020 yÄ±lÄ±nda ne eÄŸitimde ne istihdamda olan genÃ§lerin oranÄ± nedir?":
        "2020 yÄ±lÄ±nda ne eÄŸitimde ne istihdamda olan genÃ§lerin oranÄ± %28,3 oldu",

    "2023 yÄ±lÄ±nda internet kullanan genÃ§lerin oranÄ± nedir?":
        "2023 yÄ±lÄ±nda internet kullanan genÃ§lerin oranÄ± %97,5 oldu",

    "2024 yÄ±lÄ±nda yaÅŸlÄ± nÃ¼fus kaÃ§ kiÅŸidir?":
        "2024 yÄ±lÄ±nda yaÅŸlÄ± nÃ¼fus 9 milyon 112 bin 298 kiÅŸi oldu"
}

def norm_q(s: str) -> str:
    return re.sub(r"\s+", " ", s.strip().lower())

GROUND_TRUTH_MAP_N = {norm_q(k): v for k, v in GROUND_TRUTH_MAP.items()}



# ============================================
# ANA ALAN
# ============================================

# EÄŸer sistem hazÄ±rsa chat gÃ¶ster
if st.session_state.retriever:
    
    # RAG chain oluÅŸtur
    rag_chain = create_rag_chain_no_retriever()
    
    st.subheader("ğŸ’¬ Sohbet")
    
    # Mesaj geÃ§miÅŸini gÃ¶ster
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            
            # EÄŸer kaynaklar varsa gÃ¶ster
            if message["role"] == "assistant" and "sources" in message:
                with st.expander("ğŸ“š Kaynaklar"):
                    for i, source in enumerate(message["sources"], 1):
                        st.markdown(f"**Kaynak {i}:** {source['source']}")
                        st.markdown(f"*Kategori:* {source['kategori']} | *YÄ±l:* {source['yil']}")
                        st.text(source['content'][:200] + "...")
                        st.divider()
    
    # KullanÄ±cÄ± giriÅŸi
    if prompt := st.chat_input("Sorunuzu sorun..."):
        # KullanÄ±cÄ± mesajÄ±
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # Bot cevabÄ±
        with st.chat_message("assistant"):
            with st.spinner("DÃ¼ÅŸÃ¼nÃ¼yorum..."):
                # tek retrieval (akÄ±llÄ±)
                retrieved_docs = retrieve_docs_smart(prompt)

                if not retrieved_docs:
                    response = "Bu bilgi verilen dokÃ¼manlarda bulunmamaktadÄ±r."
                    contexts = []
                elif guard:= (guard_mismatch(prompt, retrieved_docs)):
                    response = "Bu bilgi verilen dokÃ¼manlarda bulunmamaktadÄ±r."
                    contexts = [doc.page_content for doc in retrieved_docs]
                else:
                    context_text = format_docs(retrieved_docs)
                    response = rag_chain.invoke({"context": context_text, "question": prompt})
                    contexts = [doc.page_content for doc in retrieved_docs]

                # Ground truth ekle
                gt = GROUND_TRUTH_MAP_N.get(norm_q(prompt), "")
                # RAGAS iÃ§in sakla (modelin gÃ¶rdÃ¼ÄŸÃ¼ context ile aynÄ±!)
                st.session_state.contexts[prompt] = {
                    "question": prompt,
                    "answer": response,
                    "contexts": contexts,
                    "ground_truth": gt
                    

                }

                st.markdown(response)
                
                # KaynaklarÄ± gÃ¶ster
                sources = []
                for doc in retrieved_docs:
                    sources.append({
                        "source": doc.metadata.get('source', 'Bilinmiyor'),
                        "kategori": doc.metadata.get('kategori', '-'),
                        "yil": doc.metadata.get('yil', '-'),
                        "content": doc.page_content
                    })
                
                with st.expander("ğŸ“š Kaynaklar"):
                    for i, source in enumerate(sources, 1):
                        st.markdown(f"**Kaynak {i}:** {source['source']}")
                        st.markdown(f"*Kategori:* {source['kategori']} | *YÄ±l:* {source['yil']}")
                        st.text(source['content'][:200] + "...")
                        st.divider()
        
        # MesajÄ± kaydet
        st.session_state.messages.append({
            "role": "assistant", 
            "content": response,
            "sources": sources
        })

else:
    # Sistem hazÄ±r deÄŸilse bilgilendirme
    st.info("ğŸ‘ˆ LÃ¼tfen sol menÃ¼den PDF'leri iÅŸleyip veritabanÄ±nÄ± oluÅŸturun.")
    
    st.markdown("### ğŸ“‹ Ã–rnek Sorular")
    st.markdown("""
    - 2020 yÄ±lÄ±nda genÃ§lerin iÅŸsizlik oranÄ± nedir?
    - 2014 ile 2024 arasÄ±nda aile yapÄ±sÄ± nasÄ±l deÄŸiÅŸti?
    - YaÅŸlÄ± nÃ¼fus oranÄ± yÄ±llara gÃ¶re nasÄ±l bir trend gÃ¶steriyor?
    - En son yÄ±l iÃ§in genÃ§lik istatistikleri nedir?
    - Hangi yÄ±llarda evlilik oranÄ± en yÃ¼ksekti?
    """)
    
    st.markdown("### ğŸ“Š Sistem Ã–zellikleri")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Model", "GPT-4o Mini")
        st.metric("Embedding", "text-embedding-3-small")
    
    with col2:
        st.metric("Chunk Size", CHUNK_SIZE)
        st.metric("Chunk Overlap", CHUNK_OVERLAP)
    
    with col3:
        st.metric("Top-K", TOP_K)
        st.metric("Temperature", 0.1)

# ============================================
# ALT BÄ°LGÄ°
# ============================================

st.divider()

col1, col2, col3 = st.columns(3)

with col1:
    if st.session_state.messages:
        if st.button("ğŸ§¹ Sohbeti Temizle"):
            st.session_state.messages = []
            st.session_state.contexts = {}
            st.rerun()

with col2:
    if st.session_state.contexts:
        st.info(f"âœ… {len(st.session_state.contexts)} soru RAGAS iÃ§in hazÄ±r")

with col3:
    if st.button("ğŸ“ˆ RAGAS DeÄŸerlendirmesine Git"):
        st.switch_page("pages/ragas_evaluation.py")




import os
import re
import streamlit as st
from dotenv import load_dotenv
from pathlib import Path
from typing import List, Dict

from langchain_core.documents import Document
from langchain_chroma import Chroma
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter

# ============================================
# YAPILANDIRMA
# ============================================

load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    st.error("âš ï¸ LÃ¼tfen .env dosyasÄ±na OPENAI_API_KEY ekleyin.")
    st.stop()

# Sabitler
BASE_DIR = Path(__file__).resolve().parent
DATA_FOLDER = str(BASE_DIR / "data")
PERSIST_DIR = str(BASE_DIR / "chroma_db")
CHUNK_SIZE = 600
CHUNK_OVERLAP = 120
TOP_K = 4

# Streamlit yapÄ±landÄ±rma
st.set_page_config(
    page_title="TÃœÄ°K Ä°statistik Chatbot",
    page_icon="ğŸ“Š",
    layout="wide"
)

# LLM ve Embeddings
llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0, max_tokens=1000, api_key=api_key)
embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
# Session state baÅŸlatma
for key, default in [
    ("vector_store", None),
    ("retriever", None),
    ("messages", []),
    ("contexts", {})
]:
    if key not in st.session_state:
        st.session_state[key] = default

# Ground truth verileri
GROUND_TRUTH = {
    "2020 yÄ±lÄ±nda genÃ§ nÃ¼fus oranÄ± nedir?": "2020 yÄ±lÄ±nda genÃ§ nÃ¼fus, toplam nÃ¼fusun %15,4'Ã¼nÃ¼ oluÅŸturdu.",
    "2023 yÄ±lÄ±nda akraba evliliÄŸi oranÄ± nedir?": "2023 yÄ±lÄ±nda akraba evliliÄŸi yapanlarÄ±n oranÄ± %8,2 oldu",
    "2014 yÄ±lÄ±nda boÅŸanan Ã§ift sayÄ±sÄ± kaÃ§tÄ±r?": "BoÅŸanan Ã§ift sayÄ±sÄ± 2014 yÄ±lÄ±nda 130 bin 913 oldu",
    "2018 yÄ±lÄ±nda genÃ§lerde iÅŸsizlik oranÄ± nedir?": "2018 yÄ±lÄ±nda genÃ§lerde iÅŸsizlik oranÄ± %20,3 oldu",
    "2020 yÄ±lÄ±nda ne eÄŸitimde ne istihdamda olan genÃ§lerin oranÄ± nedir?": "2020 yÄ±lÄ±nda ne eÄŸitimde ne istihdamda olan genÃ§lerin oranÄ± %28,3 oldu",
    "2023 yÄ±lÄ±nda internet kullanan genÃ§lerin oranÄ± nedir?": "2023 yÄ±lÄ±nda internet kullanan genÃ§lerin oranÄ± %97,5 oldu",
    "2024 yÄ±lÄ±nda yaÅŸlÄ± nÃ¼fus kaÃ§ kiÅŸidir?": "2024 yÄ±lÄ±nda yaÅŸlÄ± nÃ¼fus 9 milyon 112 bin 298 kiÅŸi oldu"
}

# Normalize edilmiÅŸ ground truth
GROUND_TRUTH_NORM = {
    re.sub(r"\s+", " ", k.strip().lower()): v 
    for k, v in GROUND_TRUTH.items()
}

# ============================================
# YARDIMCI FONKSÄ°YONLAR
# ============================================

def extract_metadata(filename: str) -> Dict[str, str]:
    """Dosya adÄ±ndan kategori ve yÄ±l Ã§Ä±kar."""
    metadata = {"kategori": "bilinmiyor", "yil": "bilinmiyor"}
    
    filename_lower = filename.lower()
    if "genclik" in filename_lower:
        metadata["kategori"] = "genclik"
    elif "yasli" in filename_lower:
        metadata["kategori"] = "yasli"
    elif "aile" in filename_lower:
        metadata["kategori"] = "aile"
    
    year_match = re.search(r'_(\d{2})\.pdf', filename)
    if year_match:
        metadata["yil"] = f"20{year_match.group(1)}"
    
    return metadata

def load_pdfs(data_folder: str) -> List[Document]:
    """TÃ¼m PDF'leri yÃ¼kle ve metadata ekle."""
    if not os.path.exists(data_folder):
        st.error(f"âŒ {data_folder} klasÃ¶rÃ¼ bulunamadÄ±!")
        return []
    
    pdf_files = [f for f in os.listdir(data_folder) if f.lower().endswith('.pdf')]
    if not pdf_files:
        st.warning(f"âš ï¸ {data_folder} klasÃ¶rÃ¼nde PDF bulunamadÄ±!")
        return []
    
    all_documents = []
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for idx, pdf_file in enumerate(pdf_files):
        status_text.text(f"YÃ¼kleniyor: {pdf_file}")
        
        try:
            loader = PyPDFLoader(os.path.join(data_folder, pdf_file))
            documents = loader.load()
            file_metadata = extract_metadata(pdf_file)
            
            for doc in documents:
                doc.metadata.update({
                    "source": pdf_file,
                    **file_metadata
                })
            
            all_documents.extend(documents)
        except Exception as e:
            st.warning(f"âš ï¸ {pdf_file} yÃ¼klenemedi: {str(e)}")
        
        progress_bar.progress((idx + 1) / len(pdf_files))
    
    progress_bar.empty()
    status_text.empty()
    
    return all_documents

def create_vector_store(documents: List[Document]) -> Chroma:
    """VektÃ¶r veritabanÄ± oluÅŸtur."""
    with st.spinner("ğŸ“ DokÃ¼manlar parÃ§alanÄ±yor..."):
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=CHUNK_SIZE,
            chunk_overlap=CHUNK_OVERLAP,
            separators=["\n\n", "\n", ".", "!", "?", ",", " ", ""]
        )
        splits = splitter.split_documents(documents)
        st.info(f"âœ‚ï¸ Toplam {len(splits)} metin parÃ§asÄ± oluÅŸturuldu")
    
    with st.spinner("ğŸ”¢ Embeddings hesaplanÄ±yor..."):
        return Chroma.from_documents(
            documents=splits,
            embedding=embeddings,
            persist_directory=PERSIST_DIR
        )

def extract_years(text: str) -> List[str]:
    """Metinden yÄ±l Ã§Ä±kar."""
    years = re.findall(r"\b(20\d{2})\b", text)
    return list(dict.fromkeys(years))  # SÄ±rayÄ± koruyarak unique yap

def retrieve_docs(question: str) -> List[Document]:
    """AkÄ±llÄ± dÃ¶kÃ¼man retrieval."""
    years = extract_years(question)
    k = 12 if len(years) >= 2 else TOP_K
    
    docs_all = []
    
    # YÄ±l bazlÄ± filtreleme
    if years and st.session_state.vector_store:
        for year in years:
            retriever = st.session_state.vector_store.as_retriever(
                search_kwargs={"k": k, "filter": {"yil": year}}
            )
            docs_all.extend(retriever.invoke(question))
        
        # Fallback: az sonuÃ§ varsa genel arama
        if len(docs_all) < min(4, k):
            fallback = st.session_state.vector_store.as_retriever(
                search_kwargs={"k": k}
            )
            docs_all.extend(fallback.invoke(question))
    else:
        docs_all = st.session_state.retriever.invoke(question)
    
    # TekrarlarÄ± kaldÄ±r
    unique_docs = []
    seen = set()
    for doc in docs_all:
        key = (
            doc.metadata.get("source"),
            doc.metadata.get("page"),
            doc.metadata.get("kategori"),
            doc.metadata.get("yil"),
            doc.page_content[:120]
        )
        if key not in seen:
            seen.add(key)
            unique_docs.append(doc)
    
    return unique_docs

def guard_mismatch(question: str, docs: List[Document]) -> bool:
    """Kavram uyumsuzluÄŸu kontrolÃ¼."""
    q = question.lower()
    ctx = " ".join(d.page_content for d in docs).lower()
    
    # YaÅŸlÄ± nÃ¼fus oranÄ± vs yaÅŸlÄ± baÄŸÄ±mlÄ±lÄ±k oranÄ±
    if "yaÅŸlÄ± nÃ¼fus oran" in q and "yaÅŸlÄ± baÄŸÄ±mlÄ±lÄ±k oran" in ctx and "yaÅŸlÄ± nÃ¼fus oran" not in ctx:
        return True
    
    # Beklenen yaÅŸam sÃ¼resi tÃ¼rleri
    if "beklenen yaÅŸam sÃ¼resi" in q:
        if "doÄŸuÅŸta" in q and ("65 yaÅŸ" in ctx or "65 yaÅŸÄ±nda" in ctx) and "doÄŸuÅŸta" not in ctx:
            return True
        if ("65 yaÅŸ" in q or "65 yaÅŸÄ±nda" in q) and "doÄŸuÅŸta" in ctx and "65 yaÅŸ" not in ctx and "65 yaÅŸÄ±nda" not in ctx:
            return True
    
    return False

def format_docs(docs: List[Document]) -> str:
    """DÃ¶kÃ¼manlarÄ± formatla."""
    formatted = []
    for i, doc in enumerate(docs, 1):
        kategori = doc.metadata.get('kategori', 'bilinmiyor').upper()
        yil = doc.metadata.get('yil', 'bilinmiyor')
        formatted.append(f"[Kaynak {i} - {kategori} {yil}]\n{doc.page_content}\n")
    return "\n".join(formatted)

def init_vector_store():
    """VektÃ¶r veritabanÄ±nÄ± baÅŸlat veya yÃ¼kle."""
    if os.path.exists(PERSIST_DIR) and os.listdir(PERSIST_DIR):
        return Chroma(persist_directory=PERSIST_DIR, embedding_function=embeddings)
    
    documents = load_pdfs(DATA_FOLDER)
    if not documents:
        st.error(f"Veri bulunamadÄ±: {DATA_FOLDER}")
        return None
    
    return create_vector_store(documents)

def create_rag_chain():
    """RAG chain oluÅŸtur."""
    template = """Sen TÃœÄ°K istatistik uzmanÄ±sÄ±n. Soruyu DOÄRUDAN ve KISACA cevapla.

BaÄŸlam:
{context}

Soru:
{question}

CEVAP KURALLARI:
1. Soruyu DOÄRUDAN cevapla - gereksiz aÃ§Ä±klama yapma
2. SADECE sorulan bilgiyi ver - ek detay ekleme
3. SayÄ±sal bilgi varsa: "2023 yÄ±lÄ±nda oran %15,4'tÃ¼r." formatÄ±nda ver
4. KarÅŸÄ±laÅŸtÄ±rma isteniyorsa: KÄ±sa tablo veya liste kullan
5. "BaÄŸlama gÃ¶re...", "Kaynaklara gÃ¶re..." gibi giriÅŸler kullanma
6. Kavram uyumsuzluÄŸu varsa: "Bu bilgi dokÃ¼manlarda bulunmamaktadÄ±r."

YASAKLAR:
âŒ "Tabii ki", "Elbette", "Maalesef" gibi dolgu kelimeler
âŒ BaÄŸlamda olmayan genel bilgiler
âŒ "DÃ¼nya", "Avrupa", "OECD" karÅŸÄ±laÅŸtÄ±rmalarÄ± (baÄŸlamda yoksa)
âŒ Kavram karÄ±ÅŸtÄ±rma: "yaÅŸlÄ± nÃ¼fus oranÄ±" â‰  "yaÅŸlÄ± baÄŸÄ±mlÄ±lÄ±k oranÄ±"

Ã–rnek Ä°yi Cevap:
Soru: "2020'de genÃ§ iÅŸsizlik oranÄ± nedir?"
Cevap: "2020 yÄ±lÄ±nda genÃ§ iÅŸsizlik oranÄ± %25,9'dur."

CEVAP (sadece cevap, baÅŸka hiÃ§bir ÅŸey yazma):"""
    prompt = ChatPromptTemplate.from_template(template)
    return prompt | llm | StrOutputParser()

# ============================================
# BAÅLATMA
# ============================================

if st.session_state.vector_store is None:
    st.session_state.vector_store = init_vector_store()

if st.session_state.vector_store and st.session_state.retriever is None:
    st.session_state.retriever = st.session_state.vector_store.as_retriever(
        search_kwargs={"k": TOP_K}
    )

# ============================================
# ANA UYGULAMA
# ============================================

st.title("ğŸ“Š TÃ¼rkiye GenÃ§lik, Aile ve YaÅŸlÄ± Ä°statistikleri Chatbot")
st.caption("OpenAI GPT + RAGAS ile performans deÄŸerlendirmeli versiyon")

if st.session_state.retriever:
    rag_chain = create_rag_chain()
    
    st.subheader("ğŸ’¬ Sohbet")
    
    # Mesaj geÃ§miÅŸi
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            
            if message["role"] == "assistant" and "sources" in message:
                with st.expander("ğŸ“š Kaynaklar"):
                    for i, source in enumerate(message["sources"], 1):
                        st.markdown(f"**Kaynak {i}:** {source['source']}")
                        st.markdown(f"*Kategori:* {source['kategori']} | *YÄ±l:* {source['yil']}")
                        st.text(source['content'][:200] + "...")
                        st.divider()
    
    # KullanÄ±cÄ± giriÅŸi
    if prompt := st.chat_input("Sorunuzu sorun..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        with st.chat_message("user"):
            st.markdown(prompt)
        
        with st.chat_message("assistant"):
            with st.spinner("DÃ¼ÅŸÃ¼nÃ¼yorum..."):
                retrieved_docs = retrieve_docs(prompt)
                
                if not retrieved_docs:
                    response = "Bu bilgi verilen dokÃ¼manlarda bulunmamaktadÄ±r."
                    contexts = []
                elif guard_mismatch(prompt, retrieved_docs):
                    response = "Bu bilgi verilen dokÃ¼manlarda bulunmamaktadÄ±r."
                    contexts = [doc.page_content for doc in retrieved_docs]
                else:
                    context_text = format_docs(retrieved_docs)
                    response = rag_chain.invoke({"context": context_text, "question": prompt})
                    contexts = [doc.page_content for doc in retrieved_docs]
                
                # Ground truth ve context kaydet
                norm_question = re.sub(r"\s+", " ", prompt.strip().lower())
                st.session_state.contexts[prompt] = {
                    "question": prompt,
                    "answer": response,
                    "contexts": contexts,
                    "ground_truth": GROUND_TRUTH_NORM.get(norm_question, "")
                }
                
                st.markdown(response)
                
                # KaynaklarÄ± gÃ¶ster
                sources = [
                    {
                        "source": doc.metadata.get('source', 'Bilinmiyor'),
                        "kategori": doc.metadata.get('kategori', '-'),
                        "yil": doc.metadata.get('yil', '-'),
                        "content": doc.page_content
                    }
                    for doc in retrieved_docs
                ]
                
                with st.expander("ğŸ“š Kaynaklar"):
                    for i, source in enumerate(sources, 1):
                        st.markdown(f"**Kaynak {i}:** {source['source']}")
                        st.markdown(f"*Kategori:* {source['kategori']} | *YÄ±l:* {source['yil']}")
                        st.text(source['content'][:200] + "...")
                        st.divider()
        
        st.session_state.messages.append({
            "role": "assistant",
            "content": response,
            "sources": sources
        })

else:
    st.info("ğŸ‘ˆ LÃ¼tfen sol menÃ¼den PDF'leri iÅŸleyip veritabanÄ±nÄ± oluÅŸturun.")
    
    st.markdown("### ğŸ“‹ Ã–rnek Sorular")
    st.markdown("""
    - 2020 yÄ±lÄ±nda genÃ§lerin iÅŸsizlik oranÄ± nedir?
    - 2014 ile 2024 arasÄ±nda aile yapÄ±sÄ± nasÄ±l deÄŸiÅŸti?
    - YaÅŸlÄ± nÃ¼fus oranÄ± yÄ±llara gÃ¶re nasÄ±l bir trend gÃ¶steriyor?
    - En son yÄ±l iÃ§in genÃ§lik istatistikleri nedir?
    - Hangi yÄ±llarda evlilik oranÄ± en yÃ¼ksekti?
    """)
    
    st.markdown("### ğŸ“Š Sistem Ã–zellikleri")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Model", "GPT-4o Mini")
        st.metric("Embedding", "text-embedding-3-small")
    
    with col2:
        st.metric("Chunk Size", CHUNK_SIZE)
        st.metric("Chunk Overlap", CHUNK_OVERLAP)
    
    with col3:
        st.metric("Top-K", TOP_K)
        st.metric("Temperature", 0)

# ============================================
# ALT BÄ°LGÄ°
# ============================================

st.divider()
col1, col2, col3 = st.columns(3)

with col1:
    if st.session_state.messages:
        if st.button("ğŸ§¹ Sohbeti Temizle"):
            st.session_state.messages = []
            st.session_state.contexts = {}
            st.rerun()

with col2:
    if st.session_state.contexts:
        st.info(f"âœ… {len(st.session_state.contexts)} soru RAGAS iÃ§in hazÄ±r")

with col3:
    if st.button("ğŸ“ˆ RAGAS DeÄŸerlendirmesine Git"):
        st.switch_page("pages/ragas_evaluation.py")